{
  
    
        "post0": {
            "title": "Binding Site Comparison Benchmarks - I",
            "content": "Summary . In this article I&#39;ll go through the overall thought process of setting up a benchmark set. For the sake of simplicity I&#39;ll do it for a single target to evaluate the performance of a binding site comparison algorithm. I&#39;ll try to provide code whenever possible against public resources or snippets if a bit of scripting is needed. When the public domain information is insufficient, I might fall back to resources like 3decision, MOE families, which is not public domain knowledge, but can very much help fulfill the task at hand. . The target binding site . In order to show the overall process, let&#39;s start with a well studied target &amp; relatively easy target, HSP90. A usual guinea pig since my PhD in Xavier Barril&#39;s lab, but it&#39;s a good example to show without exploring too much in super large protein families in the beginning. I aim to apply the process outlined here later to a thrombin, a trypsin like serine protease, which will likely involve some adjustments. . HSP90 . The heat shock protein 90 is a rather abundant protein in the cell and helps during protein folding of not yet formed proteins, or protects already folded proteins from external stress (thermal stress for instance) - thus HSP = Heat Shock Protein. Let&#39;s start with HSP90 alpha from the homo sapiens, even though they are common among eucaryotes. Several kinases are dependent (activated) on HSP90, especially those acting as hub. This is one of the reasons why HSP90 has been investigated as potential drug target for treatment of several forms of cancer. The action of HSP is dependent on ATP and the dephosphorylation of this molecule &amp; the ATP binding site is located on a particular are in the N-terminal part of HSP90. This will be the binding site to focus on here. . Why HSP90 as a first example . HSP90 has a lot of structures available in the public domain. | It&#39;s not part of any gigantic protein family (kinases, GPCR&#39;s etc), which keeps the initial comparison space to cover a bit smaller. | The fold of the protein is still conserved among several other proteins, so there&#39;s matter for detecting expected similarities | It binds ATP, such as a lot of proteins in nature - which is interesting for the if I bind the same molecule I must be similar conundrum. | The binding site can undergo important conformational changes, which is good to evaluate sensity on conformation | Water plays a very important role upon binding of small molecules into the ATP binding site | . Domain architecture . HSP90 alpha human is composed of two domains: . the N-terminal Histidine kinase, DNA gyrase B and HSP90-like ATPase domain (ranging from amino acid 40 to 193) | the C-terminal HSP90 protein domain (196-714) | . The ATP binding site of interest is on the N-terminal part and this is the part that you have the most crystal strucutres for in the RCSB today. A full length Alphafold model available in the public domain. NB: there appears to be another ATP binding site on the C-terminal part, that is only accessible when activated - so interesting to maybe look out for that one as well. . The topology of the ATP binding site (N-ter) . import nglview view = nglview.show_pdbid(&quot;3t0z&quot;) # load &quot;3pqr&quot; from RCSB PDB and display viewer widget view.representations = [ {&quot;type&quot;: &quot;cartoon&quot;, &quot;params&quot;: { &quot;sele&quot;: &quot;protein&quot;, &quot;color&quot;: &quot;residueindex&quot; }}, {&quot;type&quot;: &quot;ball+stick&quot;, &quot;params&quot;: { &quot;sele&quot;: &quot;hetero&quot;,&quot;color&quot;:&quot;element&quot; }}, {&quot;type&quot;: &quot;ball+stick&quot;, &quot;params&quot;: { &quot;sele&quot;: &quot;hetero and _C&quot;, &quot;color&quot;:&quot;yellow&quot; }}, {&quot;type&quot;: &quot;licorice&quot;, &quot;params&quot;: { &quot;sele&quot;: &quot;47-55 or 91 or 93 or 96-97 or 98 or 102 or 106 or 107 or 112 or 132-139 or 150 or 162 or or 186 &quot;, &quot;color&quot;: &quot;element&quot; }},{&quot;type&quot;: &quot;contact&quot;, &quot;params&quot;: { &quot;sele&quot;: &quot;47-55 or 93 or 96-97 or 98 or 102 or 106 or 107 or 112 or 132-139 or 150 or 162 or ligand or water&quot;, &quot;color&quot;: &quot;element&quot; }} ] view.camera = &#39;orthographic&#39; view.background = &#39;black&#39; view . . The binding site is composed of a section containing the adenin moety which is characterized by a beta sheet at the bottom of the site, and two helices lining the site. The sidechains exposed to the binding site lumen are globally hydrophobic, a part from the very important aspartate 93, which is interacting directly with the adenine moeity. The adenin moeity is sourrounded by water molecules and several of these watersare important hallmarks of several HSP90 binders. The ribose moeity is not forming any H-bonds with the protein itself but has hydroxyls oriented towards the solvent. The ether of the ribose is orented towards the valine 107, adjacent to a rather hydrophobic part of the pocket coated by Y139, F138 and W162. The triphospate is solvent exposed and interacting with a small helix-loop-helix motive which, as we will probably see a bit later part of the more mobile regions of the binding site. . Establishing a reference set . Now we have defined a binding site of interest, let&#39;s try to establish first a few obvious scenarios one might want to cover with a pocket comparison method. In my previous post I stated that the principle use case for binding site comparison methods that I&#39;m focusing on is large scale comparison or screening. The underlying use cases that I&#39;m mainly interested in are NOT protein function prediction, but rather the prediction of potential counter targets, or extracting bound ligands from related binding sites to inform structurally during my compound design cycle. . Let&#39;s consider that we are working on a drug design project on the HSP90 N-terminal ATP binding site and we have our favourite structure of HSP90 as starting point, i.e. 4cwr. . If I want to find similar binding sites to my query binding site vs all known/putative binding sites, what hits I&#39;d expect to get first in the hitlist ?: . the ATP binding site of other HSP90 alpha human structures with the same overall conformation (more or less) - same sequence &amp; conformation | the ATP binding site of other HSP90 human isoforms with a similar conformation - likely locally identical sequences &amp; conformation | the ATP binding site of HSP90 sequences from other species with a similar conformation - locally very similar sequences | all of the above but with a bit different conformations - conformations | the ATP binding site of close homologs (sequence - families etc) to the query structure - similar sequences | the ATP binding sites of proteins sharing the same fold as HSP90 - same fold | nucleotide binding sites with similar interaction patterns but dissimar fold - same interactions | all binding sites binding ATP must be similar (provocative on purpose ...) - same ligand | unexpected &amp; unrelated / unknown similarities - nightmare | These first five give a graduation up to which level another ATP binding site could be potentially close to the HSP90 binding site. These are the obvious clusters of sequences, structures &amp; conformations one would expect to find. As a result, one can use this type of graduation also for validating binding site comparison methods. One major difference with the setting I&#39;m laying out here, is that the background data encompasses the full RCSB PDB structures containing all ligand binding sites + putative binding sites (empty clefts). This sets the approach I&#39;m suggesting into stark contrast with previous benchmark sets. Such previous sets were classically composed of a list of expected matches of binding site pairs and decoys (expected mismatches). As Vincent Le Guilloux, if you can avoid a threshold effect, avoid it! This is exactly such a case where a discrete split between a match &amp; a mismatch is introduced. As a result my background data (what one usually calls a decoy) is the full pocketome and I&#39;ll try to use metrics of success that measure, how many of the potentially expected hits are found before a bulk of less expected hits &amp; why. . In the subsequent sections I&#39;ll go through all the painful steps to create the dataset corresponding to each of the sections 1 to 5. The situation 6 &amp; 7 are a bit more tricky to set up. As for 8 - that&#39;s the big issue with binding site comparison benchmarking - you don&#39;t know until you know, but I&#39;ll try to do a bit of my homework on that as well! . 1. Same Sequence &amp; conformation . Alright, here we go ... the same sequence is the easiest case of all of them &amp; several previous studies included a selection of structures, but as you&#39;ll see even here to do things properly it gets quickly tricky. The following script will cover the required steps: . gather all structures (PDB codes) containing a resolved HSP90 alpha human N terminal domain | filter out structures with mutations on binding site residues compared to the wild type | get an all by all comparison of the binding sites (structurally speaking) which would allow for some rough clustering of conformations | . SCOP classification . If one considers that the SCOP family of this domain will likely contain other HSP90 Nter ATP binding sites then this is a useful resource to look for already assigned similarities by protein fold classification. This has been used already in several other papers in the litterature, but let&#39;s exemplify here for the sake of completeness. . The N-ter ATP binding domain of HSP90 and the hierarchy of SCOP classifications can be found here. . .",
            "url": "https://pschmidtke.github.io/blog/binding%20site/pocket/cavity/pocket%20comparison/structure-based%20drug%20design/2023/04/03/binding-site-comparison-benchmark-I.html",
            "relUrl": "/binding%20site/pocket/cavity/pocket%20comparison/structure-based%20drug%20design/2023/04/03/binding-site-comparison-benchmark-I.html",
            "date": " • Apr 3, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "Binding site comparison - current benchmark issues",
            "content": "Intro . First of all, what is written here is my personal viewpoint on the matter. It is conceivable that other people might have different opinions on this topic ;) . There has been a lot of interest on the comparison (in 3D) of binding sites since initiating work in that scope by Jambon et al. Today several methods exist, some of them freely available and some of them ... not. I also got sucked into the field by the end of my PhD but never ended writing up papers about the whole topic. There are several reasons for that. The main one is likely laziness and total frustration with the scientific publishing &amp; reviewing process. So now I decided to write things up gradually here and maybe one day I&#39;ll spend some time shaping that into a paper ;) This post is mainly about the shortcomings in the way these algorithms are generally validated &amp; intends to challenge currently accepted benchmark datasets in the field. NB: my focus here is to validate at some point my own algorithms, but given the state of the art, a bit of work on the datasets themselves is in order! Also, I&#39;m focusing on how can such binding site methods be applied in the context of drug-discovery when sieving through all structural information available within resources like the RCSB PDB or a model database, like Alphafold or derivatives. . What is binding site comparison? . In its simplest form, the fact to be able to compare two pockets from two structures and assess to what extent they are similar. I guess you can already see the various pitfalls in this definition. Binding site comparison could have some rather nice applications when applied on a larger scale (compare one or multiple binding sites to millions of others) in order to identify potential off-targets (or promiscuity prediction) or chemical matter that might bind in such an environment (drug repurposing or bioisosteric replacements, fragment based designs etc ...). Comparing binding sites is not a trivial task and the perception on how this should be done can vary significantly depending on the use-case or mind-set at hand. Here are some potential use cases that require dedicated datasets &amp; validation: . idea generation in drug discovery (hit id &amp; lead opt) | polypharmacology prediction (toxicology) | protein function prediction | . Existing literature . Today there are a lot of papers published on that topic. As usual with method development papers in science, with them a ton of ways proving that the authors&#39; method is for sure always the best one compared to a small selected set of the other existing ones ... The field of binding site comparison lacked for a very long time a throuroughly built &amp; commonly accepted benchmark dataset and this for various reasons. But in the end, we end up with the typical mess with a ton of methods each better than the other but not really comparable nor compared to one another. . Prospeccts . A recent (well now not so recent anymore ...) review article by Christiane Ehrt, Tobias Brinkhorst &amp; Oliver Koch tries to address some of the historical shortcomings in the field. They summarize some approaches known today (not extensive, but representative). You can find them in table 1 of the paper available here: (!https://journals.plos.org/ploscompbiol/article/figure?id=10.1371/journal.pcbi.1006483.t001). I fully understand that benchmarking a posteriori tens of different methods &amp; developers must be daunting task &amp; am really grateful the team tackled such an effort. . The paper reuses / discusses some of the older datasets in the litterature, and I&#39;ll cover mainly two of the ones used by the authors. . Ehrt et al also touch upon a different topic in that paper: a dataset to benchmark a method depends on the scope of capabilities you want to test your method on. That&#39;s a reality that was simply absent from validations before. If you want to prove that your method is capable of detecting remote relationships between binding sites on very different proteins known to bind similar ligands (or not), you have to actually validate that on a relevant dataset. . TOUGH dataset . Link to the paper This dataset was introduced by Govindaraj &amp; Brylinski the same year as the publication of prospeccts. It is an interesting one, because it focuses on one of the &quot;dreams&quot; in the binding site comparison community: &quot;Two very different binding sites known to bind a similar ligand, must be to some extent similar&quot;. I&#39;ll come to that statement a bit later. Basically their viewpoint is that some of the previous studies had performances published that were too good, because the underlying protein structures used in the binding site comparison evaluation were too similar. . So they set up a process to generate a more challenging (&quot;tough&quot;) dataset for such methods as described in figure 1 of that paper . I&#39;m currently still trying to wrap my head around the actual procedure and its potential advantages &amp; drawbacks but have to admit that the process is as so often not reproducible as is. So one has to live with the dataset established in 2018, which itself also difficult to reproduce for reasons I won&#39;t elaborate further - but a few lines of code from a paper about deeplytough from benevolent actually helped to get to the actual dataset at least. . Kahraman dataset . Link to paper That&#39;s historically the most used &amp; cited one in the field and it was developed for a totally different purpose. To highlight that, find here the abstract from that paper: . Most function prediction methods that identify cognate ligands from binding site analyses work on the assumption of molecular complementarity. These approaches build on the conjectured complementarity of geometrical and physicochemical properties between ligands and binding sites so that similar binding sites will bind similar ligands. We found that this assumption does not generally hold for protein–ligand interactions and observed that it is not the chemical composition of ligand molecules that dictates the complementarity between protein and ligand molecules, but that the ligand&#39;s share within the functional mechanism of a protein determines the degree of complementarity. Here, we present for a set of cognate ligands a descriptive analysis and comparison of the physicochemical properties that each ligand experiences in various nonhomologous binding pockets. The comparisons in each ligand set reveal large variations in their experienced physicochemical properties, suggesting that the same ligand can bind to distinct physicochemical environments. In some protein ligand complexes, the variation was found to correlate with the electrochemical characteristic of ligand molecules, whereas in others it was disclosed as a prerequisite for the biochemical function of the protein. To achieve binding, proteins were observed to engage in subtle balancing acts between electrostatic and hydrophobic interactions to generate stabilizing free energies of binding. For the presented analysis, a new method for scoring hydrophobicity from molecular environments was developed showing high correlations with experimental determined desolvation energies. The presented results highlight the complexities of molecular recognition and underline the challenges of computational structural biology in developing methods to detect these important subtleties. Proteins 2010. © 2009 Wiley-Liss, Inc. . How on earth did this end up as benchmark dataset for binding site comparison? The conclusions of that paper are a very interesting read and if you have the chance to have access to the paper I invite you to read them. . Similar binding sites bind similar ligands and vice versa . The titel of this section summarizes a general assumption in the field for validating binding site comparison algorithms. . Let me list a few citations here to clarify my point: . Our approach makes the basic assumption that proteins which bind similar ligands have clefts of similar size, shape and chemistry. from Morris et al and the authors of the Kahraman paper above ... &gt; Similarity in ligand binding sites can indicate common binding modes and recognition of similar molecules ... from Gold and Jackson&gt; Assuming that similar ligands bind to similar cavities, function and ligands for a novel protein may be inferred from structurally similar liganded cavities from Weill et al And there are many more. Interestingly, this statement has been the basis to establish some of the first binding site comparison benchmarks used in the litterature and the example cited about the TOUGH dataset above. . This results in a very early and widely used benchmark dataset of 40 structures binding either a steroid, NAD, ATP and heme groups. You can already imagine that in terms of applications to drug-discovery this might be of limited interest. What is more disturbing to me here, establishing these sets (and others around the same principle), is that if a protein binds the same ligand, its binding site should be somehow related / similar to some extent. Yes in some cases that&#39;s true, but using it as a ground truth statement is an oversimplification. . According to what we know so far (or at least that&#39;s how I understood it), a binding site can be promiscuous and ligands can be promiscuous as well. There are very well known examples of proteins binding a whole range of ligands even though their binding sites have nothing in common with the intended target in the drug discovery project. Take for instance the HERG channel or CYP P450 ... all of them are able to bind a variety of ligands despite the disimilarity of their binding sites compared to the intended targets. Another hallmark of such promiscuous binding sites is their hydrophobicity and presence of short sidechains in the binding vicinity (Cerisier et al cited above) - this poses particular challenges to binding site comparison methods as stated as well by Ehrt et al. And these are only unwanted off-targets we know about because they impede on how you imagine your drug interacts inside and outside the cell. . On the other hand, ligands can also expose particular functional groups that yield either very specific interactions and thus a narrow biological profile (hitting only a few targets), or on the contrary, they can bind on a large variety of binding sites of different proteins (frequent hitters, promiscuous binders and all of the molecules in the shadow zone in between promiscuous and specific). . Also, in order to establish datasets based on this assumption one requires the actual data, so reliable structures with compound A in target X and a similar compound B in totally different target Y and their exact location of interaction. If your compound B has a very narrow biological footprint (hits only a few targets specifically) then you might be lucky. However, if your compound B is a frequent hitter then what is the relevance of that relation? You&#39;d associate target X to a whole lot of other targets hit by a promiscuous compound. . When using binding site comparison methods in the scope of protein function prediction such approximation might be relevant or event wanted. However I doubt they should have such a high relevance in the scope of drug discovery applications. . A paper that sets all of this a bit more in the perspective of drug discovery was written by Barelier, Sterling, O&#39;Meara &amp; Shoichet in 2015. But even there one can observe important shortcomings. . A few current benchmark datasets . A quick peek into the TOUGH-M1 dataset . The paper introducing the TOUGH dataset didn&#39;t include a single figure showing what types of binding sites &amp; thus ligands were selected to establish the benchmark dataset. So to get a glimpse of that here I&#39;ll show a set of the most common clusters of molecules in their &quot;positive&quot; dataset, so a set of binding sites to be compared to others binding similar ligands. . A bit of code . Let&#39;s read in the positive list from the TOUGH-M1 dataset and read all sd files available in the distributed version of the dataset. . # prerequisit: get the zip file and unzip to a folder of your choice: wget https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/L7H7JJ/UFO5CB # get the positive list from the TOUGH-M1 set from the SI of the paper itself import pandas as pd from pathlib import Path from rdkit import Chem from rdkit import RDLogger lg = RDLogger.logger() lg.setLevel(RDLogger.CRITICAL) positiveList=pd.read_csv(&quot;/Users/peter/Downloads/TOUGH-M1_positive.list&quot;,delim_whitespace=True) uniquePdbCodes=positiveList.iloc[:, 0].unique() print(&quot;Number of distinct PDB structures: {}&quot;.format(len(uniquePdbCodes))) molecules=[] for pdbCode in uniquePdbCodes: sdFilePath=&#39;/Users/peter/Downloads/TOUGH-M1_dataset/&#39;+pdbCode+&#39;/&#39;+pdbCode+&#39;00.sdf&#39; for mol in Chem.SDMolSupplier(sdFilePath,removeHs=False,sanitize=True): if mol: mol.RemoveAllConformers() molecules.append(mol) print(&quot;Read {} molecules&quot;.format(len(molecules))) . . Number of distinct PDB structures: 5965 Read 5917 molecules . First of all you notice that a few molecules cannot be read. I won&#39;t go too much into detail, but feel free to peek in here which ones these are &amp; how this could happen. Now let&#39;s do a very basic clustering just to get a rough idea on what the dataset looks like. . from rdkit.Chem import AllChem import numpy as np #Define clustering setup def ClusterFps(fps,cutoff=0.2): from rdkit import DataStructs from rdkit.ML.Cluster import Butina # first generate the distance matrix: dists = [] nfps = len(fps) for i in range(1,nfps): sims = DataStructs.BulkTanimotoSimilarity(fps[i],fps[:i]) dists.extend([1-x for x in sims]) cs = Butina.ClusterData(dists,nfps,cutoff,isDistData=True) return cs fps = [AllChem.GetMorganFingerprintAsBitVect(mol,2,1024) for mol in molecules if mol] clusters=ClusterFps(fps,cutoff=0.4) clusterSizes=np.array([len(cluster) for cluster in clusters]) sortedClusterIndices=np.argsort(clusterSizes)[::-1] selectedSizes=clusterSizes[sortedClusterIndices] from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole mols=[molecules[clusters[sortedClusterIndices[idx]][0]] for idx in range(0,50)] legend=[&quot;Cluster &quot;+str(sortedClusterIndices[idx])+&quot; - &quot;+str(s) for idx,s in enumerate(selectedSizes[:50])] Draw.MolsToGridImage(mols,molsPerRow=5,legends=legend) . . # Here is a bit of code if you want ot get a peek into each cluster, did that but won&#39;t show the results. Overall they look fairly clean: #mols=[molecules[clusters[sortedClusterIndices[0]][idx]] for idx in range(0,50)] #Draw.MolsToGridImage(mols,molsPerRow=5) . . Results . The majority of the dataset is composed of nucleotides /-sides, sugars &amp; derivatives ... ah and hemes. We can also find what we usually would consider as crystallographic surfactants, very small fragments, and a few lipids as well. In other words, the overall composition of the dataset appears to be somehow close to the Kahraman dataset despite being on a different scale (5000 structures versus 40 roughly). Here again I’d argue that such a dataset is useful in the scope of protein function prediction, but I doubt it’s the best suited for drug discovery. . How about Prospeccts . During my binding site comparison tests, I also played a bit more in detail with the Prospeccts dataset 1 &amp; 7. . Dataset 1 . It tries to give indicators on how sensitive a comparison method is towards the binding site definition itself. It&#39;s composed of 12 different protein binding sites that can be identified relatively easily with the table S9 from supporting information. Several structures are available for each binding site and a binding site comparison algorithm should ideally be able to identify binding sites of the same protein with higher similarities than binding sites of the other proteins of the dataset (used as decoy here). The authors state, that &quot;It was generated to evaluate the sensitivity of binding site comparison tools with respect to the binding site definition. A tool which is not able to enrich similar binding sites accommodating different ligands should not be applied for drug repurposing projects or the prediction of putative off-targets&quot;. The second sentence, does not really apply for this dataset in my opinion. I used this kind of approach though to test if naturally a binding site comparison method is able to enrich results (from a huge heterogeneous set of pockets) with binding sites from the same protein (same location) or protein family, or orthologs. Ehrt et al argue that the benchmark set depend on the purpose of the binding site comparison sofware and that&#39;s true. Datasets like the dataset 1 from the Prospeccts paper allow first of all to check if there is some reasonable signal in identifying similar binding sites. I&#39;m saying binding sites, not interaction patterns (!!!). As such, dataset 1 &amp; thoroughly built extensions of these can be used to evaluate if a binding site comparison method could be used also as idea generator and for validation of off-target identification scenarios (but there aren&#39;t any in dataset 1 as for now). . Dataset 7 . This dataset from the prospeccts paper is one of these examples where you say, on paper that looks great and about what we need. But once looking into the details, it&#39;s again rather small and there are a few very worrying errors in it as well (i.e. two PIM kinase ATP binding sites as decoy pair, a lot of NAD / FAD binding sites etc). . How about the Barelier dataset . Let&#39;s check out the Barelier dataset, which again is supposed to give us a few examples where the same or similar ligands bind to very different proteins. Again this is used throughout the binding site comparison community as valid benchmark dataset. The set is rather small, so I&#39;ll just display the chemical matter that has been used here. The Barelier set is also used within the prospeccts paper. The molecules were extracted from the residue codes available in table1 SI - class A (ligands make similar interactions in related residues in both binding sites), table 2 SI - class B (same ligand groups interact with dissimilar residues &amp; environments)), table 3 SI - class C (different parts of the ligand interacts). . from rdkit.Chem import AllChem from rdkit import Chem import numpy as np import requests import json #I love copying codes from PDF&#39;s, ACS, you cannot imagine how painful this is classA=[&quot;2AN&quot;,&quot;3IP&quot;,&quot;ACD&quot;,&quot;AEF&quot;,&quot;AGI&quot;,&quot;AMZ&quot;,&quot;BRN&quot;,&quot;CAU&quot;,&quot;DAO&quot;,&quot;CXX&quot;,&quot;EIC&quot;,&quot;FLN&quot;,&quot;GNT&quot;,&quot;HXA&quot;,&quot;IBP&quot;,&quot;NTZ&quot;,&quot;VCA&quot;,&quot;X8Z&quot;] classB=[&quot;0YN&quot;,&quot;IGP&quot;,&quot;1QK&quot;,&quot;4AX&quot;,&quot;4HP&quot;,&quot;4NP&quot;,&quot;ALE&quot;,&quot;BIO&quot;,&quot;C2R&quot;,&quot;CEL&quot;,&quot;CFF&quot;,&quot;CPB&quot;,&quot;CSN&quot;,&quot;DHF&quot;,&quot;XDE&quot;,&quot;EMO&quot;,&quot;ES1&quot;,&quot;FUN&quot;,&quot;H2B&quot;,&quot;IAC&quot;,&quot;LOC&quot;,&quot;LVA&quot;,&quot;MTE&quot;,&quot;MYC&quot;,&quot;NAR&quot;,&quot;OCA&quot;,&quot;PDN&quot;,&quot;PT1&quot;] classC=[&quot;16A&quot;,&quot;2AL&quot;,&quot;2TN&quot;,&quot;3PO&quot;,&quot;AIN&quot;,&quot;AZM&quot;,&quot;BER&quot;,&quot;CLM&quot;,&quot;EMU&quot;,&quot;FLF&quot;,&quot;IAC&quot;,&quot;LUM&quot;,&quot;PHN&quot;] def getMoleculesFromRcsb(residueCode): response=requests.get(&quot;https://data.rcsb.org/rest/v1/core/chemcomp/&quot;+residueCode) if(response.status_code==requests.codes.ok): d=json.loads((response.text)) smiles=d[&quot;rcsb_chem_comp_descriptor&quot;][&quot;smiles&quot;] return(Chem.MolFromSmiles(smiles)) return None classAmolecules=[getMoleculesFromRcsb(residue) for residue in classA] classBmolecules=[getMoleculesFromRcsb(residue) for residue in classB] classCmolecules=[getMoleculesFromRcsb(residue) for residue in classC] . . Class A molecules . #collapse-hide Draw.MolsToGridImage(classAmolecules,molsPerRow=5) . . Class B molecules . Draw.MolsToGridImage(classBmolecules,molsPerRow=5) . . Class C molecules . Draw.MolsToGridImage(classCmolecules,molsPerRow=5) . . An overall observation is that several molecules in all three classes are rather fragments than actual specific drug-like molecules. This is usually a warning sign on the reliability of the structure &amp; the positioning of the fragment itself. There are several examples underlinging these limitations, but one of the more recent ones can be found here. The dataset also contains saturated &amp; unsaturated alkyl chains or fatty acids. Obtaining any sort of specificity in purely hydrophobic binding sites is not straightforward to say the least. We find yet again several nucleosides or derivatives. Last, some molecules wouldn&#39;t even pass filters like PAINS or such. . General Note . While browsing through the litterature and the SI associated to various binding site comparison papers using &quot;benchmark&quot; sets, I found it rather difficult to get a good understanding of what the actual binding site encompassed. So, on top of the composition of the benchmark sets, I think one could do better in litterature on communicating the location of binding sites (i.e. pdb code, chain(s), ligand residue code (and chain), list of residues (and chain)). This would help solving some ambiguities when trying to use such datasets on not so trivial cases, like several conformations of NMR structures, binding sites encompassing other small molecules (are they considered to be part of the binding site or not) like dihydrofolate reductase etc. Working with lists of residues would also help to add protein protein interfaces in the list of examples (I didn&#39;t see ANY example in the benchmark set) and one could even consider having a canonical list of residues per protein among a list of structures. . Similar folds contain similar binding sites . Another way to assess binding site comparison algorithms is to check whether they are able to find binding sites that are part of different proteins but the same or similar SCOP families. SCOP is a structural classification of proteins by fold. . SCOP is regularly used to assess whether two proteins have overall structural similarities (for instance here and here ) but I haven&#39;t seen a paper building an actual consistent benchmark set from SCOP &amp; other information as well (comments are welcome, I guess I have missed something in the existing litterature). . For example, HSP90, DNA topoisomerase II &amp; histidine kinases are all in the same SCOP family and they all share a common fold on the ATP binding site, even though there are local dissimilarities. . Example of a superimposition done with 3decision between three unrelated proteins but similar folds (HSP90 holo structure 4cwr, histidine kinase apo 1ys3 and a DNA gyrase B holo structure 4hz5) - typically difficult to superpose with i.e. PyMOL . Here the local similarities are obvious: beta-sheet at the bottom of the ATP binding site with a very well conserved aspartate, three binding site lining helices. However, the actual conformations, breaks &amp; extent of the helices differs a lot between the three structures taken as an example here. . Perspective . Summing up I&#39;ll try to work on establishing one or two novel sets along the following principles when trying to find similar binding sites from a large collection of binding sites (like all known or putative binding sites from the RCSB) . it should be purely structure based (no ligands / interactions involved &amp; encompass apo structures as well) | what is obviously similar should be retrieved first (higher similarities) | what is objectively similar (like the example from the SCOP family above) should also be retrieved with lower similarity to the previous | a hand picked &amp; human validated set of structural similarities between totally unrelated proteins / structures / binding sites, but might be less similar than the above | no explicit definiton of decoys | What is obviously similar should be retrieved first . When searching large collections of structures having a single or a set of binding sites as query, I&#39;d expect to find the structures of the same protein containing the same binding site with no or few changes (mutations, flexibility) before any other hits (proteins / binding sites), unless these other hits are locally as similar as the query protein structures themselves. This can / should happen for close homologs in common protein families. . What is objectively similar . That&#39;s a principle that is easy to say, but not as easy to verify &amp; implement. While the previous point was scoped on the same or similar sequence space (protein families, homologs), this one should check known obvious similarities, like same fold &amp; minor mutations / flexibility in the binding site. . Totally unrelated proteins . Tricky, but that&#39;s what a lot of academics seem to focus on. . No explicit definition of decoys . That&#39;s another not so trivial thing, but typically in the prospeccts paper (and others) decoys are usually defined as pairs of binding sites that shouldn&#39;t match. For similar reasons as with decoys in virtual screening experiments, when there is no actual experimental proof that a decoy is a decoy one shouldn&#39;t use it as a decoy. Not to mention biases this introduces intrinsically as well. If no decoys are available, we won&#39;t be able however to compare against ROC curves vs the litterature, if that was to be our aim. Rather than following that path, I&#39;d set up binding site similarity searches against all known &amp; putative pockets and evaluate how much of what I should get out from a similarity search, I actually get out. .",
            "url": "https://pschmidtke.github.io/blog/binding%20site/pocket/cavity/pocket%20comparison/structure-based%20drug%20design/2022/11/07/binding-site-comparison-benchmark.html",
            "relUrl": "/binding%20site/pocket/cavity/pocket%20comparison/structure-based%20drug%20design/2022/11/07/binding-site-comparison-benchmark.html",
            "date": " • Nov 7, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Torsion angle scan with rdkit & xtb",
            "content": "Post #4 will be along the lines of dihedral / torsion angle analysis again. The aim is to log some of the hurdles I had to overcome to run a torsion angle analysis with xtb and / or rdkit. . What I&#39;m trying to accomplish here is mainly to see how torsion angle scans can be performed - easily and robustly - using open source tools available. This is in preparation of a larger work track on analysing the data from the COD, where first steps have already been set here. . Aim . Given an input molecule and a particular torsion angle I&#39;d like to see what the energy langscape of the molecule looks like when rotating around that torsion angle. I&#39;d like to know how easy/complicated this is using two different tools: . rdkit with the integrated MMFF | xtb from the Grimme lab | The post is also inspired by an older post done by iwatobipen analyzing openforcefield with Ani2 on some torsion energy predictions using the torsion drive dataset from the openforcefield initiative . All code used for this post is available on this separate repo, as it uses a slightly different environment (you&#39;ll see why). . Dihedral scan with rdkit . I don&#39;t really know why, but I started out with this molecule here: . from rdkit import Chem from rdkit.Chem import AllChem from rdkit.Chem import Draw mol=Chem.AddHs(Chem.MolFromSmiles(&#39;CCCOC1=CC=C(Cl)C(C)=C1&#39;)) for i, a in enumerate(mol.GetAtoms()): a.SetAtomMapNum(i) AllChem.EmbedMolecule(mol,randomSeed=10) #generate an initial random conformation (randomSeed is fixed to have something reproducible) #mol Draw.MolToFile(mol,&quot;../images/mol.png&quot;,includeAtomNumbers=True,highlightAtoms=(1,2,3,4)) #sorry - rdkit 2019.03 issues with newer python versions (I guess) . . . The torsion angle I&#39;m interested in is highlighted in red and situated between carbons 1,2,3 &amp; 4. Now let&#39;s try to set up a torsion angle scan in rdkit using MMFF (UFF should be similar procedure ... ) . from rdkit.Chem import rdMolTransforms import altair as alt import copy import pandas as pd from rdkit.Chem import rdForceFieldHelpers from rdkit.Chem import ChemicalForceFields conformer=mol.GetConformer(0) m2=copy.deepcopy(mol) mp2 = AllChem.MMFFGetMoleculeProperties(m2) energy=[] confid=0 angles=range(0,370,10) for angle in angles: confid+=1 ff2 = AllChem.MMFFGetMoleculeForceField(m2, mp2) ff2.MMFFAddTorsionConstraint(1,2,3,4, False, angle - .1, angle + .1, 10000.0) ff2.Minimize() energy.append(ff2.CalcEnergy()) xyz=ff2.Positions() new_conf = Chem.Conformer(mol.GetNumAtoms()) for i in range(mol.GetNumAtoms()): new_conf.SetAtomPosition(i, (m2.GetConformer(-1).GetAtomPosition(i))) new_conf.SetId(confid) mol.AddConformer(new_conf) dfrdkit = pd.DataFrame({&#39;angle&#39;:angles, &#39;energy&#39;:energy}) alt.Chart(dfrdkit).mark_line(point=True,interpolate=&quot;natural&quot;).encode( alt.X(&#39;angle:Q&#39;, scale=alt.Scale(domain=[0,360,350]) ), alt.Y(&#39;energy:Q&#39;, scale=alt.Scale(zero=False) ) ).interactive() . RDKit issues . Alright, first of all ... to run all of these I have to use rdkit 2019.03.3 or earlier!! as since then there has been obviously a regression on the MMFF &amp; UFF torsion constrain code (or other). You can track this issue on github directly for newer rdkit versions. But in the end, this basically means you cannot run any of this with newer rdkit versions, which is suboptimal. . Next, seeing this plot above, it doesn&#39;t look anything like the one I expected from the torsion archive (but a bit better than on the new bugged rdkit, believe me ;)). Here is the one from iwatobipen&#39;s post: . . In order to understand what happens here, you really have to look at the minimized conformations. Here&#39;s a bit of code to browse through them. I collected all conformations generated with the torsion scan before. . from ipywidgets import interact, interactive, fixed import py3Dmol patt = Chem.MolFromSmarts(&#39;c1ccccc1&#39;);patt match = mol.GetSubstructMatch(patt) AllChem.AlignMolConformers(mol,atomIds=match) def drawit(m,p,confId): mb = Chem.MolToMolBlock(m,confId=confId) p.removeAllModels() p.addModel(mb,&#39;sdf&#39;) p.setStyle({&#39;stick&#39;:{}}) #p.zoomTo() return p.show() viewer = py3Dmol.view(width=500, height=500) mb = Chem.MolToMolBlock(mol,confId=0) viewer.addModel(mb,&#39;sdf&#39;) viewer.setStyle({&#39;stick&#39;:{}}) viewer.zoomTo() #viewer.show() conformerIds=[conf.GetId() for conf in mol.GetConformers()] interact(drawit, m=fixed(mol),p=fixed(viewer),confId=(0,mol.GetNumConformers()-1)) . . &lt;function __main__.drawit(m, p, confId)&gt; . You can use the slider above to browse through the first conformers. You&#39;ll see that essentially conformers 1 to 5 are wrong. So likely I&#39;m doing something very wrong here (I followed some sample code on that from Jason Biggs posted in the github issue on that) or there&#39;s still another bug. Digging a bit deeper into this issue I found that this might come from the out of plane terms of the MMFF in rdkit. To double check that we can actually rerun the whole thing without out of plane energy terms - sorry a bit verbose the code here: WARNING: The interactive widget doesn&#39;t seem to render on fastpages (the framework I use for the blog) - so you&#39;ll have to run the piece of code manually on your side to see all of these or check out the binder link above (wait till the full environment is built). For the sake of clarity a py3dmol session of conformation 1 below so you see the issue: . viewer = py3Dmol.view(width=500, height=500) mb = Chem.MolToMolBlock(mol,confId=1) viewer.addModel(mb,&#39;sdf&#39;) viewer.setStyle({&#39;stick&#39;:{}}) viewer.zoomTo() viewer.show() . . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . from rdkit.Chem import rdMolTransforms import altair as alt import copy import pandas as pd from rdkit.Chem import rdForceFieldHelpers from rdkit.Chem import ChemicalForceFields mol=Chem.AddHs(Chem.MolFromSmiles(&#39;CCCOC1=CC=C(Cl)C(C)=C1&#39;)) for i, a in enumerate(mol.GetAtoms()): a.SetAtomMapNum(i) AllChem.EmbedMolecule(mol,randomSeed=10) conformer=mol.GetConformer(0) m2=copy.deepcopy(mol) mp = AllChem.MMFFGetMoleculeProperties(m2) mp.SetMMFFOopTerm(False) # That&#39;s the critical bit here - switch off out of plane terms for MMFF ffm = AllChem.MMFFGetMoleculeForceField(m2, mp) energy=[] confid=0 angles=range(0,370,10) for angle in angles: confid+=1 ff2 = AllChem.MMFFGetMoleculeForceField(m2, mp) ff2.MMFFAddTorsionConstraint(1,2,3,4, False, angle - .1, angle + .1, 10000.0) ff2.Minimize() energy.append(ff2.CalcEnergy()) xyz=ff2.Positions() new_conf = Chem.Conformer(mol.GetNumAtoms()) for i in range(mol.GetNumAtoms()): new_conf.SetAtomPosition(i, (m2.GetConformer(-1).GetAtomPosition(i))) new_conf.SetId(confid) mol.AddConformer(new_conf) dfrdkit = pd.DataFrame({&#39;angle&#39;:angles, &#39;energy&#39;:energy}) alt.Chart(dfrdkit).mark_line(point=True,interpolate=&quot;natural&quot;).encode( alt.X(&#39;angle:Q&#39;, scale=alt.Scale(domain=[0,360,350]) ), alt.Y(&#39;energy:Q&#39;, scale=alt.Scale(zero=False) ) ).interactive() . Well, that looks slightly more reasonable in terms of positions of the energy wells. We see a minimum at 180°, other minimas around 75° and 275° &amp; and energy peak around 0°. This is a bit more in line with what we might expect here. You can browse through the conformations below. They look more reasonable as well now: . from ipywidgets import interact, interactive, fixed import py3Dmol patt = Chem.MolFromSmarts(&#39;c1ccccc1&#39;);patt match = mol.GetSubstructMatch(patt) AllChem.AlignMolConformers(mol,atomIds=match) def drawit(m,p,confId): mb = Chem.MolToMolBlock(m,confId=confId) p.removeAllModels() p.addModel(mb,&#39;sdf&#39;) p.setStyle({&#39;stick&#39;:{}}) return p.show() viewer = py3Dmol.view(width=500, height=500) mb = Chem.MolToMolBlock(mol,confId=0) viewer.addModel(mb,&#39;sdf&#39;) viewer.setStyle({&#39;stick&#39;:{}}) viewer.zoomTo() conformerIds=[conf.GetId() for conf in mol.GetConformers()] interact(drawit, m=fixed(mol),p=fixed(viewer),confId=(0,mol.GetNumConformers()-1)) . . &lt;function __main__.drawit(m, p, confId)&gt; . So the bottomline here is at least in this example the out of plane terms are not living well together with my other dihedral constraints. . Dihedral scan with xtb . XTB is a toolkit implementing semiempirical quantum mechanics and you can do quite a lot of things. Among these: energy optimization, dihedral scans, constrained optimizations, metadynamics etc...It&#39;s conda packaged, so easy to deploy anywhere. In contrary to things like Gaussian, Jaguar etc, it&#39;s: . free | opensource | actually quite fast | Running an energy optimization with xtb is rather straightforward and would work like this: . xtb mol.sdf --opt --charge 0 . This will write the optimized molecule in an SD file, together with the energy (in hartree). . XTB also supports dihedral scans as described in the documentation and the examples work well on ethane. The thing is, as usual ... we are not working with ethane or 1-Bromo-2-chloroethane (the other example). . Long story short, I tried to integrate a dihedral scan as described in the documentation, but on my molecule above (which still remains rather simple) . This resulted in a ton of segmentation faults (fond memories of Gaussian came back to me) after a few dihedral scan cycles. My suspicion is that the xtb optimizer is not robust enough to allow to resolve really ugly clashes generated during the scan (I&#39;m just guessing here). . So here&#39;s the workaround I came up with: preparing &quot;good enough&quot; starting conformations with rdkit and constrained optimizing with xtb and last, gathering the final energy values. Given the issues with the out of plane terms before I would have preferred having a self contained and functioning way to do this with xtb, but well...there are days like these. . import os angles=range(0,370,10) xtbenergy=[] #loop over the previous conformations we obtained with rdkit for idx,deg in enumerate(angles): w = Chem.SDWriter(&#39;mol.sdf&#39;) w.write(mol,confId=idx+1) w.close() atoms = &#39;2,3,4,5&#39; #set atoms to define the dihedral - NB: xtb indexes start at 1, rdkit at 0 # Now write the xtb input file: fh = open(&quot;dihedral_constraint.inp&quot;,&quot;w&quot;) fh.write(&quot;&quot;&quot;$constrain force constant=1.00 dihedral: {},{} $end&quot;&quot;&quot;.format(atoms,float(deg))) fh.close() # run xtb os.system(&quot;export OMP_STACKSIZE=48G &amp;&amp; export OMP_NUM_THREADS=12,1 &amp;&amp; xtb mol.sdf --opt vtight --charge 0 --input dihedral_constraint.inp&quot;) sdr=Chem.SDMolSupplier(&quot;xtbopt.sdf&quot;) for xtbmol in sdr: xtbenergy.append(xtbmol.GetProp(&quot;total energy / Eh&quot;)) . This runs for a while, but it&#39;s still reasonably fast. Also, you might have noticed that I specified an argument to the --opt flag. This argument allows you to tweak how loose or precise the optimisation should be. More information on that can be found in the xtb documentation here. In this example I specified a rather precise method. Feel free to play around with them and check the outcome (rather interesting as well). . import numpy as np angle=np.array(range(0,370,10)) dfxtb = pd.DataFrame({&#39;angle&#39;:angle, &#39;xtb&#39;:xtbenergy,&#39;MMFF&#39;:dfrdkit[&quot;energy&quot;]}) base = alt.Chart(dfxtb).encode( alt.X(&#39;angle:Q&#39;, axis=alt.Axis(title=None),scale=alt.Scale(domain=[0,360,350])) ) line1 = base.mark_line(stroke=&#39;#5276A7&#39;, interpolate=&#39;natural&#39;).encode( alt.Y(&#39;xtb:Q&#39;, axis=alt.Axis(title=&#39;xtb energy&#39;, titleColor=&#39;#5276A7&#39;),scale=alt.Scale(zero=False)) ) line2 = base.mark_line(stroke=&#39;#57A44C&#39;, interpolate=&#39;natural&#39;).encode( alt.Y(&#39;MMFF:Q&#39;, axis=alt.Axis(title=&#39;MMFF energy&#39;, titleColor=&#39;#57A44C&#39;),scale=alt.Scale(zero=False)) ) alt.layer(line1, line2).resolve_scale( y = &#39;independent&#39; ) . On this plot we can see both results, from rdkit&#39;s MMFF implementation and xtb. Good news...at least they agree on the maximum around 0°. Other than that there are quite important discrepancies on the location of the global minimum and the importance &amp; extent of the energy barriers between them. Interestingly, openFF and ani2 also predict 180° as a global minimum. . Comparing vs COD . Let&#39;s double check these results now with the initial work done on the COD (not yet cleaned and curated - so there will be some noise in here still). This is for sure not the only experimental data-source one should use, but I&#39;ll define it as my golden source of truth here within the scope of this post. First I&#39;ll try to identify the smarts patterns from the torsion library that match the dihedral under investigation here: . patterns=pd.read_table(&quot;../data/list_torsion_patterns.txt&quot;,header=None,usecols=[1]) selectedPatterns=[] for torsionSmarts in patterns[1]: torsionQuery = Chem.MolFromSmarts(torsionSmarts) matches = mol.GetSubstructMatches(torsionQuery) if(len(matches)&gt;0): if (matches==((1,2,3,4),)): selectedPatterns.append(torsionQuery) print(&quot;selected: &quot;,torsionSmarts) . selected: [C:1][CX4H2:2]!@;-[OX2:3][c:4] selected: [!#1:1][CX4H2:2]!@;-[OX2:3][c:4] selected: [C:1][CX4H2:2]!@;-[OX2:3][!#1:4] selected: [!#1:1][CX4H2:2]!@;-[OX2:3][!#1:4] selected: [!#1:1][CX4:2]!@;-[OX2:3][!#1:4] . Now we have the selected patterns, let&#39;s run these through the prepared COD molecules (a huge local sd file right now) and gather statistics on angles. NB: the smart patterns used here might be redundant and map the same molecules. So here I&#39;m keeping track of which molecule was previously selected and don&#39;t include it in a subsequent calculation anymore: . suppl = Chem.SDMolSupplier(&#39;out.sdf&#39;,removeHs=False) #load the COD sd angles=[] matchingmols=[] for pattern in selectedPatterns: print(Chem.MolToSmarts(pattern)) # based on the gist from Geoff Hutchison: https://gist.github.com/ghutchis/b388dd83ddcd7dc0be11f1ed72309da2 index_map = {} for atom in pattern.GetAtoms() : map_num = atom.GetAtomMapNum() if map_num: index_map[map_num-1] = atom.GetIdx() map_list = [index_map[x] for x in sorted(index_map)] #i=0 #suppl.reset() nMols = len(suppl) for i in range(nMols): mol=suppl[i] #for mol in suppl: # i+=1 if mol is None: continue if (i not in matchingmols) : conf=mol.GetConformer(0) matches = mol.GetSubstructMatches(pattern) if(len(matches)&gt;0): matchingmols.append(i) for match in matches: mapped = [match[x] for x in map_list] angle = rdMolTransforms.GetDihedralDeg(conf, mapped[0],mapped[1],mapped[2],mapped[3]) if (angle &lt; 0.0): angle += 360.0 angles.append(angle) . [C:1][C&amp;X4&amp;H2:2]!@&amp;-[O&amp;X2:3][c:4] [!#1:1][C&amp;X4&amp;H2:2]!@&amp;-[O&amp;X2:3][c:4] [C:1][C&amp;X4&amp;H2:2]!@&amp;-[O&amp;X2:3][!#1:4] [!#1:1][C&amp;X4&amp;H2:2]!@&amp;-[O&amp;X2:3][!#1:4] [!#1:1][C&amp;X4:2]!@&amp;-[O&amp;X2:3][!#1:4] . This runs again for quite some time...so patience is needed. Once this is done, you should see something like that: . alt.data_transformers.disable_max_rows() dfcod = pd.DataFrame({&#39;angles&#39;:angles}) alt.Chart(dfcod).mark_bar().encode( alt.X(&quot;angles:Q&quot;, bin=alt.Bin(maxbins=100)), y=&#39;count()&#39;, ) . . intervals=pd.interval_range(start=0, end=360,periods=37) codangles=pd.cut(angles, bins=intervals).value_counts() . dfall = pd.DataFrame({&#39;angle&#39;:range(0,370,10), &#39;xtb&#39;:xtbenergy,&#39;MMFF&#39;:dfrdkit[&quot;energy&quot;],&#39;cod&#39;:np.array(codangles)}) #print(dfall) #data = dfxtb.melt(&#39;angle&#39;) base = alt.Chart(dfall).encode( alt.X(&#39;angle:Q&#39;, axis=alt.Axis(title=None),scale=alt.Scale(domain=[0,360,350])) ) line1 = base.mark_line(stroke=&#39;#5276A7&#39;, interpolate=&#39;natural&#39;).encode( alt.Y(&#39;xtb:Q&#39;, axis=alt.Axis(title=&#39;xtb energy&#39;, titleColor=&#39;#5276A7&#39;),scale=alt.Scale(zero=False)) ) line2 = base.mark_line(stroke=&#39;#57A44C&#39;, interpolate=&#39;natural&#39;).encode( alt.Y(&#39;MMFF:Q&#39;, axis=alt.Axis(title=&#39;MMFF energy&#39;, titleColor=&#39;#57A44C&#39;),scale=alt.Scale(zero=False)) ) line3 = base.mark_line(stroke=&#39;#ff0000&#39;, interpolate=&#39;natural&#39;).encode( alt.Y(&#39;cod:Q&#39;, axis=alt.Axis(title=&#39;COD angles&#39;, titleColor=&#39;#ff0000&#39;),scale=alt.Scale(zero=False)) ) alt.layer(line1, line2,line3).resolve_scale( y = &#39;independent&#39; ) . So here we have in red the results from the COD, in green MMFF from rdkit and xtb in blue. Good news is that the positions of the wells seem to be estimated rather well with xtb. MMFF seems slightly off for the preference on 280°. Analysing relative energy differences between local minima, xtb doesn&#39;t follow the trend observed using MMFF &amp; results from the COD here. . Conclusion . Initially I wanted to run this on a larger set of molecules, but as usual things turn out to be much less robust than anticipated. So more to come in an upcoming post, on other torsion angles - especially the challenging ones. . The encouraging aspect here is, that despite all difficulties, one could potentially use this on a larger set of molecules. The instability of xtb on the integrated dihedral scan should be investigated a bit further as well ... essentially to make sure that this is not only due to my totally &quot;noob&quot; use of the toolkit - which is very likely. .",
            "url": "https://pschmidtke.github.io/blog/torsion/dihedral/oss/opensource/rdkit/xtb/energy/2021/02/16/torsion-angle-scans-xtb.html",
            "relUrl": "/torsion/dihedral/oss/opensource/rdkit/xtb/energy/2021/02/16/torsion-angle-scans-xtb.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "fpocket 4.0 - Towards biologics",
            "content": "I just released the last version of fpocket (4.0) which contains quite a few new features. Most of the work was done by Mael Shorkar, an eager summer intern we took in at Discngine during last year&#39;s COVID-mess summer. He did a great job under these circumstances (remote work in a new company etc). So kudos to him for these new additions. . MMCIF support . First of all, fpocket now supports mmCIF. Yay ... yet another very painful task to integrate for yet another painfully crappy molecular file format (I admire the openbabel folks ... ;) ). Same as for the PDB format we forked essentially an integration from the VMD molfile plugin and extended that a bit further. Mael also integrated mmCIF writers so all output files can be written in this new crappy format as well. Essentially you now have the choice to write either only pdb or cif or both. So everybody should be happy (nah ... that&#39;s never going to be case anyway). . New command line flags . The most interesting part (for me) of this release are additional command line flags and behind these several use cases that can be addressed now. These command line arguments enable mainly to work in a more controlled way with multi chain protein structures. This can be particularly useful if: . you want to study only one domain of one of these novel gigantic cryoEM structures | you want to study in detail a protein - biomolecule binding site (so other than small molecule) | you want to learn key characteristics of peptide/protein binding sites vs RNA/DNA binding sites vs drug binding sites | -c char : (Default is none): Use this flag to choose which chains you want to delete before running fpocket. The selected chains can be specified with &#39;,&#39; or &#39;:&#39; delimiters, for example you can use it &#39;-c B,D&#39; or &#39;-c B:D&#39;. You can delete up to 20 different chains. . This flag essentially allows you to explicitly delete particular chain(s) before doing the fpocket run. This allows you to identify (without any bias) clefts that might occur on the PPI that were inaccessible before for pocket prediction. . -k char : (Default is none): Use this flag to choose which chains you want to keep before running fpocket. The selected chains can be specified with &#39;,&#39; or &#39;:&#39; delimiters, for example you can use it &#39;-k A,B,E&#39; or &#39;-k A:B:E&#39;. You can keep up to 20 different chains. . This is essentially the inverse operator of the previous flag. If you do not want to list n chains, you can decide to keep only the relevant ones here. . -a char : (Default is none): With this flag you can select a chain you want to be considered as a ligand. Works the same way as the &quot;-r&quot; flag but with a whole chain. Only a single chain can be chosen, for example &#39;-a D&#39;. . This flag essentially allows you to target for only one particular binding epitope. If you want to extract descriptors for only that binding site where the select chain is located then you can use the -a flag. Fpocket will hide the chain specified via the flag. Run vertice detection and then will choose all vertices overlapping with the chain you specified in -a. These will then be clustered together into a final &quot;pocket&quot;. This is rather generic and can be applied on protein chains, RNA, DNA ... whatever you like given that it is defined in a seperate chain. It is so generic, that in theory you can do even very nasty stuff, but let&#39;s see if you can find that out yourselves. . This argument is particularly interesting when you want to extract examples (3D patches) or numerical descriptors (polar/apolar ASA, curvature, buriedness ...) for other binding sites than classical small molecule binding sites. It essentially lies out the basics for training &amp; learning what such other binding epitopes look like. You can use that for a fancy model, or to characterize binding epitopes ultimately. . Miscellaneous . Seperately, several things were added to the github repo of fpocket, namely the old documentation was ported to markdown (that was painful). There&#39;s also a tiny testing environment, CI/CD pipes finally set up to check compilation and unit tests upon PR&#39;s. . Last, an official fpocket docker image is also available on dockerhub. . Detecting binding epitopes . Enough text now. Let&#39;s check what you can do with that now. Here we have a nice example of a TEAD4 / YAP complex. I&#39;m interested in studying the clefts covered by YAP on the TEAD4 structure. Before I essentially had to drop YAP from the PDB run fpocket and put back in YAP to see where it is located. Here YAP corresponds to chain L (the red one) and TEAD4 (the grey one). . import py3Dmol viewer = py3Dmol.view(query=&#39;pdb:6hik&#39;,width=300, height=300) viewer.setStyle({&#39;chain&#39;:&#39;A&#39;},{&#39;cartoon&#39;:{&#39;color&#39;:&#39;grey&#39;}}) viewer.setStyle({&#39;chain&#39;:&#39;L&#39;},{&#39;cartoon&#39;:{&#39;color&#39;:&#39;red&#39;}}) viewer.zoomTo() . . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f91908e3490&gt; . We can now for instance launch fpocket on TEAD4 by either dropping YAP or by keeping TEAD4 explicitly. Whatever mindset you prefer ;) Let&#39;s be in a positive mood and keep TEAD4: . fpocket -f 6hik.pdb -k A . #collapse-hide import py3Dmol viewer = py3Dmol.view(query=&#39;pdb:6hik&#39;,width=500, height=500) pdbdata=open(&#39;../data/6hik_out.pdb&#39;, &#39;r&#39;).read() viewer.addModel(pdbdata,&#39;pdb&#39;) viewer.setStyle({&#39;chain&#39;:&#39;A&#39;},{&#39;cartoon&#39;:{&#39;color&#39;:&#39;grey&#39;}}) viewer.setStyle({&#39;chain&#39;:&#39;L&#39;},{&#39;cartoon&#39;:{&#39;color&#39;:&#39;red&#39;},&#39;line&#39;:{}}) viewer.setStyle({&#39;chain&#39;:&#39;C&#39;},{&#39;sphere&#39;:{&#39;colorscheme&#39;:{&#39;prop&#39;:&#39;resi&#39;,&#39;gradient&#39;:&#39;roygb&#39;,&#39;min&#39;:1,&#39;max&#39;:15}}}) #viewer.setStyle({&#39;chain&#39;:&#39;C&#39;},{&#39;line&#39;:{&#39;colorfunc&#39;:colorAsSnake}}) viewer.zoomTo() . . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f91a08c8ac0&gt; . When doing this in an automatic way, so with classical fpocket parameters, you&#39;ll now be able to identify pockets that overlap with YAP. That&#39;s kind of nice, but what if I want to study really in detail all the binding interface itself between YAP and TEAD4? In order to instruct fpocket to define a pocket only on the interface itself you can now do something like that: . fpocket -f 6hik.pdb -a L . import py3Dmol viewer = py3Dmol.view(query=&#39;pdb:6hik&#39;,width=500, height=500) pdbdata=open(&#39;../data/6hik_out_explicit.pdb&#39;, &#39;r&#39;).read() viewer.addModel(pdbdata,&#39;pdb&#39;) viewer.setStyle({&#39;chain&#39;:&#39;A&#39;},{&#39;cartoon&#39;:{&#39;color&#39;:&#39;grey&#39;}}) viewer.setStyle({&#39;chain&#39;:&#39;L&#39;},{&#39;cartoon&#39;:{&#39;color&#39;:&#39;red&#39;},&#39;line&#39;:{}}) viewer.setStyle({&#39;chain&#39;:&#39;C&#39;},{&#39;sphere&#39;:{&#39;color&#39;:&#39;orange&#39;}}) . . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f91908e3a30&gt; . You can now get the full orange blob as the interacting epitope. Together with that you get the usual statistics etc. The cool thing is, this can be very well used on protein RNA interfaces as well. . A word on druggability . If you want to assess druggability, please use the default fpocket parameters and not a guided pocket detection or other pocket detection parameters. The druggability assessment intends to estimate a pockets tractability for small molecule binding sites. Applying this to such larger surfaces is out of the applicability domain here in my opinion. . Extracting descriptors with fpocket . Ok running these things on individual examples is nice. You can automate things with fpocket quite easily and extract descriptors on a larger scale using the fancy -d flag (oh yes, yet another flag) if the only thing you&#39;re after is descriptor extraction. . Why would I ever want to extract descriptors? . Calculating descriptors on binding epitopes is generating the basis for using these to derive several potential applications afterwards. For instance, to derive the druggability prediction in fpocket, first we extracted descriptors of known druggable and supposed non-druggable (no religious debate here) pockets, second we determined the most relevant descriptors and last we trained a scoring function based on these descriptors. . You can very well imagine to do the same on other types of binding epitopes (there are a few papers out there on that already I guess), like protein protein interfaces, antibody / antigene interfaces more specifically, crystal contacts, protein DNA/RNA interfaces etc... . Ultimately these characterisations will allow you to train functions or super fancy deep learning models (if you really need that). . In order to do that on a larger scale you could use dpocket (a less well-known sibling of fpocket), but it currently still doesn&#39;t fully integrate the logic with selecting chains as ligands (still a bit of work needed here). So let&#39;s stick to fpocket on a larger scale example for descriptor extraction which will work just fine: . data/peptide_data/3uqp.pdb B data/peptide_data/3uri.pdb B data/peptide_data/4rcp.pdb B data/peptide_data/4tpg.pdb E data/peptide_data/5jxh.pdb H . Let&#39;s suppose we have a csv file like this one above. It defines a set of PDB files and the chain we want to consider as a ligand explicitly during the fpocket run to assess the binding epitope this chain is making with the &quot;receptor&quot;. You could run this in a very geeky way using this here: . awk &#39;{ print &quot;fpocket -f &quot; $1 &quot; -a &quot;$2 &quot; -d&quot;}&#39; list.txt | sh . This will output a messy thing like this: . csv cav_id drug_score volume nb_asph inter_chain apol_asph_proportion mean_asph_radius as_density mean_asph_solv_acc mean_loc_hyd_dens flex hydrophobicity_score volume_score charge_score polarity_score a0_apol a0_pol af_apol af_pol n_abpa ala cys asp glu phe gly his ile lys leu met asn pro gln arg ser thr val trp tyr chain_1_type chain_2_type num_res_chain_1 num_res_chain_2 lig_het_tag name_chain_1 name_chain_2 1 0.0021 4091.2471 213 0 0.1831 4.3624 10.8343 0.5065 10.3590 0.0000 17.6957 4.1304 3 31 176.3137 207.7781 91.7446 196.2307 21 1 4 2 3 0 3 1 4 0 4 1 3 0 1 1 6 4 2 3 3 0 0 457 457 PSA A A cav_id drug_score volume nb_asph inter_chain apol_asph_proportion mean_asph_radius as_density mean_asph_solv_acc mean_loc_hyd_dens flex hydrophobicity_score volume_score charge_score polarity_score a0_apol a0_pol af_apol af_pol n_abpa ala cys asp glu phe gly his ile lys leu met asn pro gln arg ser thr val trp tyr chain_1_type chain_2_type num_res_chain_1 num_res_chain_2 lig_het_tag name_chain_1 name_chain_2 1 0.1847 4801.9624 204 0 0.3529 4.4814 10.8531 0.5450 22.0000 0.0000 27.5882 3.4706 -8 26 183.5595 226.1442 124.2374 226.0680 11 1 0 0 7 0 2 1 7 0 8 4 0 0 4 0 9 5 0 2 1 0 0 328 328 NULL A A cav_id drug_score volume nb_asph inter_chain apol_asph_proportion mean_asph_radius as_density mean_asph_solv_acc mean_loc_hyd_dens flex hydrophobicity_score volume_score charge_score polarity_score a0_apol a0_pol af_apol af_pol n_abpa ala cys asp glu phe gly his ile lys leu met asn pro gln arg ser thr val trp tyr chain_1_type chain_2_type num_res_chain_1 num_res_chain_2 lig_het_tag name_chain_1 name_chain_2 1 1.0000 2998.7053 187 0 0.5241 4.3207 11.5341 0.5341 48.6735 0.0000 34.3462 5.0769 3 16 107.4789 84.2598 47.7836 96.3200 8 1 2 1 2 0 0 1 1 1 1 3 3 0 3 0 1 0 1 4 1 0 0 238 238 NULL A A cav_id drug_score volume nb_asph inter_chain apol_asph_proportion mean_asph_radius as_density mean_asph_solv_acc mean_loc_hyd_dens flex hydrophobicity_score volume_score charge_score polarity_score a0_apol a0_pol af_apol af_pol n_abpa ala cys asp glu phe gly his ile lys leu met asn pro gln arg ser thr val trp tyr chain_1_type chain_2_type num_res_chain_1 num_res_chain_2 lig_het_tag name_chain_1 name_chain_2 1 0.9998 1552.9973 110 0 0.4182 4.5201 6.7627 0.4934 36.8261 0.0000 34.2593 4.8519 0 17 105.0637 48.2599 82.1878 27.8238 12 1 1 2 0 0 3 2 0 0 2 1 1 0 3 1 2 0 0 6 2 0 0 594 594 NULL A A cav_id drug_score volume nb_asph inter_chain apol_asph_proportion mean_asph_radius as_density mean_asph_solv_acc mean_loc_hyd_dens flex hydrophobicity_score volume_score charge_score polarity_score a0_apol a0_pol af_apol af_pol n_abpa ala cys asp glu phe gly his ile lys leu met asn pro gln arg ser thr val trp tyr chain_1_type chain_2_type num_res_chain_1 num_res_chain_2 lig_het_tag name_chain_1 name_chain_2 1 0.0044 3875.7029 152 0 0.1513 4.4958 9.8519 0.5972 9.5652 0.0000 -7.5946 3.4865 -7 27 114.7247 187.8280 70.7198 141.5900 15 2 3 2 8 0 0 4 4 2 0 1 0 0 0 2 2 4 1 1 1 0 0 499 499 NULL A A . Let&#39;s clean this up the geeky way: . awk &#39;{ print &quot;fpocket -f &quot; $1 &quot; -a &quot;$2 &quot; -d&quot;}&#39; list.txt | sh | awk &#39;{if(NR%2==0)print}&#39; . This should only give the descriptors: . 1 0.0021 3972.3301 213 0 0.1831 4.3624 10.8343 0.5065 10.3590 0.0000 17.6957 4.1304 3 31 176.3137 207.7781 91.7446 196.2307 21 1 4 2 3 0 3 1 4 0 4 1 3 0 1 1 6 4 2 3 3 0 0 457 457 PSA A A 1 0.1847 4604.5068 204 0 0.3529 4.4814 10.8531 0.5450 22.0000 0.0000 27.5882 3.4706 -8 26 183.5595 226.1442 124.2374 226.0680 11 1 0 0 7 0 2 1 7 0 8 4 0 0 4 0 9 5 0 2 1 0 0 328 328 NULL A A 1 1.0000 2895.7646 187 0 0.5241 4.3207 11.5341 0.5341 48.6735 0.0000 34.3462 5.0769 3 16 107.4789 84.2598 47.7836 96.3200 8 1 2 1 2 0 0 1 1 1 1 3 3 0 3 0 1 0 1 4 1 0 0 238 238 NULL A A 1 0.9998 1574.4559 110 0 0.4182 4.5201 6.7627 0.4934 36.8261 0.0000 34.2593 4.8519 0 17 105.0637 48.2599 82.1878 27.8238 12 1 1 2 0 0 3 2 0 0 2 1 1 0 3 1 2 0 0 6 2 0 0 594 594 NULL A A 1 0.0044 3794.7029 152 0 0.1513 4.4958 9.8519 0.5972 9.5652 0.0000 -7.5946 3.4865 -7 27 114.7247 187.8280 70.7198 141.5900 15 2 3 2 8 0 0 4 4 2 0 1 0 0 0 2 2 4 1 1 1 0 0 499 499 NULL A A . I did this on a larger list of peptide binding structures and this is typically a good way to start studying some of the properties of these epitopes compared to drug binding sites or others. . import pandas as pd import altair as alt d=pd.read_table(&#39;../data/peptide_out.txt&#39;,delim_whitespace=True,header=None,names=[&quot;cav_id&quot;,&quot;drug_score&quot;,&quot;volume&quot;,&quot;nb_asph&quot;,&quot;inter_chain&quot;,&quot;apol_asph_proportion&quot;,&quot;mean_asph_radius&quot;,&quot;as_density&quot;,&quot;mean_asph_solv_acc&quot;,&quot;mean_loc_hyd_dens&quot;,&quot;flex&quot;,&quot;hydrophobicity_score&quot;,&quot;volume_score&quot;,&quot;charge_score&quot;,&quot;polarity_score&quot;,&quot;a0_apol&quot;,&quot;a0_pol&quot;,&quot;af_apol&quot;,&quot;af_pol&quot;,&quot;n_abpa&quot;,&quot;ala&quot;,&quot;cys&quot;,&quot;asp&quot;,&quot;glu&quot;,&quot;phe&quot;,&quot;gly&quot;,&quot;his&quot;,&quot;ile&quot;,&quot;lys&quot;,&quot;leu&quot;,&quot;met&quot;,&quot;asn&quot;,&quot;pro&quot;,&quot;gln&quot;,&quot;arg&quot;,&quot;ser&quot;,&quot;thr&quot;,&quot;val&quot;,&quot;trp&quot;,&quot;tyr&quot;,&quot;chain_1_type&quot;,&quot;chain_2_type&quot;,&quot;num_res_chain_1&quot;,&quot;num_res_chain_2&quot;,&quot;lig_het_tag&quot;,&quot;name_chain_1&quot;,&quot;name_chain_2&quot;]) alt.Chart(d).mark_bar().encode( alt.X(&quot;volume&quot;, bin=True), y=&#39;count()&#39;, ) alt.Chart(d).transform_fold( [&#39;a0_pol&#39;, &#39;a0_apol&#39;], as_=[&#39;Columns&#39;, &#39;Values&#39;] ).mark_area( opacity=0.5, interpolate=&#39;step&#39; ).encode( alt.X(&#39;Values:Q&#39;, bin=alt.Bin(maxbins=20)), alt.Y(&#39;count()&#39;, stack=None), alt.Color(&#39;Columns:N&#39;) ) . Here we can see the distribution of polar versus apolar surface areas of these peptide binding sites under consideration. What is interesting already is that we can clearly distinguish this epitope with these descriptors alone from typical drug binding sites (more hydrophobic in general). . alt.Chart(d).mark_circle(size=60).encode( x=&#39;n_abpa&#39;, y=&#39;a0_apol&#39;, color=&#39;volume&#39;, tooltip=[&#39;drug_score&#39;, &#39;mean_asph_solv_acc&#39;, &#39;a0_apol&#39;,&#39;a0_pol&#39;,&quot;ala&quot;,&quot;cys&quot;,&quot;phe&quot;,&quot;gly&quot;,&quot;ile&quot;,&quot;leu&quot;,&quot;met&quot;,&quot;pro&quot;,&quot;val&quot;,&quot;trp&quot;,&quot;tyr&quot;] ).interactive() . The plot above is mainly to play around with altair and plottng in this blogging environment ;). However it shows the relationship between the number of ABPA&#39;s (almost burried polar atoms - if you don&#39;t know what these are, you should read this paper on shielded hydrogen bonds and the apolar surface area. Coloring done is by volume of the &quot;pocket&quot;. . Perspectives . All of these new functionalities (a part from the support of yet another &quot;useless&quot; file format) set the grounds for characterization of various types of binding epitopes using fpocket. This can terefore be used for functional characterization of protein structures, ultimately indicating where might bind what on a protein structure. . But still a few sleepless nights to go until we can achieve that. Fortunately everything is opensource, so you can do that before!!! ;) .",
            "url": "https://pschmidtke.github.io/blog/fpocket/pockets/cavity/ppi/protein/epitope/dna/rna/antibody/2021/02/02/fpocket-towards-biologics.html",
            "relUrl": "/fpocket/pockets/cavity/ppi/protein/epitope/dna/rna/antibody/2021/02/02/fpocket-towards-biologics.html",
            "date": " • Feb 2, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Crystallography Open Database and torsion angle statistics with rdkit",
            "content": "Context . When designing compounds in 3D, especially within the binding site, it is often very complicated to assess if what you&#39;ve just designed actually makes sense. Is the molecule strained? Does it make ok or favourable interactions? Does it bump into the binding site somewhere? Especially when talking to medicinal chemists, they usually want to know whether their design passes all potential physical hurdles ... and while we&#39;re at it a prediction of the binding affinity would be nice and this in 1 second. . Among all of these things to evaluate on a compound in 3D, the strain is something that can be either calculated (quantum mecanics, or force-field if you trust that) or compared to a set of reference compounds we know the structures of. . A very popular reference database for small molecule conformations is the CCDC CSD. It contains more than a million small molecule crystal structures. It is widely used in pharma industry to assess various things ... among them: ligand strain. I won&#39;t enter the debate here whether the conformations observed in small molecule crystal structures are relevant and all the other debates on the use of such a database. . The thing is, the CSD is not freely available. However, there&#39;s a free alternative available ... I guess the poor man&#39;s CSD and it&#39;s called COD for Crystallography Open Database. It contains less structures than the CSD (466 000 by the time I&#39;m writing this), that&#39;s for sure, but it&#39;s still maintained and people are depositing structures in there. The quality appears to be OK as well according to what I read so far, no tests done yet. . Here I&#39;ll outline a few steps on how to get the COD and use rdkit to extract all torsion angles of all molecules - a long and bumpy ride. Here we go. . Get the COD . That&#39;s rather easy. You can simply retrieve cif or hkl files from their server using this here: . mkdir -p cif; rsync -av --delete rsync://www.crystallography.net/cif/ cif/ . This should run for a bit. . Parsing CIF in rdkit . The first hurdle is as usual linked to molecular formats. To the best of my knowledge no cif parser was ported yet to rdkit. I tried a few parsers (gemmi - no mol or other useable output yet, pdbccdutils -&gt; only macromolecular cif files, I think) before ending up again with openbabel in the end. Let&#39;s stick with that for now. . Let&#39;s try to see what this looks like for a single cif file from the COD: . from rdkit import Chem from openbabel import pybel import py3Dmol import dask mol = next(pybel.readfile(&quot;cif&quot;, &quot;../../cod/cif/1/00/00/1000007.cif&quot;)) molblock=mol.write(&quot;mol&quot;) #write out as a molfile string and ship that now into rdkit m = Chem.MolFromMolBlock(molblock,removeHs=False) m . Well, that looks rather nasty. Let&#39;s check in 3D: . viewer = py3Dmol.view(width=300, height=300) viewer.addModel(molblock, &#39;mol&#39;) viewer.setStyle({&quot;stick&quot;:{}}) viewer.zoomTo() . . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7fc9906c7400&gt; . So good news, cif parsing seems to work (at least on this particular example). The bad news, how can I get to relevant molecules in the COD? . Extracting relevant molecules from the COD . Thanks to researchgate I came across this page where they provide a datawarrior file of the content of the cod (at least a curated subpart of that). You can see that the COD contains organic, inorganic and metalorganic structures. . . As you might already observe on the screenshot above, there&#39;s a lot of noise (for drug discovery) in there. . So how can we filter out only the organic ones? I checked the individual cif files, and no easy way to get to this classification ... would have been too easy. So two solutions - either take the prepared datawarrior file (which I would not prefer, because I&#39;m dependent on somebody else doing this nice work during his free-time, Thomas Sander), or trial and error and identify organic compounds with a set of rules. Good thing is, I can use Thomas Sanders work (the datawarrior file) to check if the filter works or not (+ visual inspection). . The COD dump you can download via rsync is structured a bit like the PDB: with two levels of subfolders, numbered and 100 files max per subfolder. Basically I&#39;ll have to loop over all of this -&gt; let&#39;s blow up the notebook ;) I&#39;ll loop over all molecules and try to run through sanitize. All failing molecules should not be added. Next I&#39;m checking as well if there&#39;s at least a carbon atom in the structure (for a lot of them there isn&#39;t). I filter out metalorganics as well. Last I keep only molecules with more than 6 atoms. . As this is a bit slow and can be easily put on several cpu&#39;s I&#39;m doing that right here as well. I wanted to test how dask behaves on such a task. It&#39;s total overkill for what I&#39;m doing here, but I want to see how the scheduling behaves on short living and often failing jobs (difficult to orchestrate, unless you handle it yourself in the code). . Below you have a standalone python script (was not optimal in the notebook) to run all of this quick and dirty preparation. There are tons of rdkit &amp; openbabel warnings popping out of that, as expected: . from rdkit import Chem from openbabel import pybel import glob import pandas as pd import os import multiprocessing as mp from wrapt_timeout_decorator import * from rdkit import rdBase rdBase.DisableLog(&#39;rdApp.error&#39;) rdBase.DisableLog(&#39;rdApp.warning&#39;) ob_log_handler = pybel.ob.OBMessageHandler() ob_log_handler.SetOutputLevel(0) carbon = Chem.MolFromSmarts(&quot;[#6]&quot;) def is_transition_metal(at): n = at.GetAtomicNum() return (n&gt;=22 and n&lt;=29) or (n&gt;=40 and n&lt;=47) or (n&gt;=72 and n&lt;=79) def write_output(filenames,outputname=&quot;out.sdf&quot;): w = Chem.SDWriter(outputname) for filename in filenames: try: if os.stat(filename).st_size / (1024 * 1024)&lt;2.0: mol = next(pybel.readfile(&quot;cif&quot;,str(filename))) molblock=mol.write(&quot;mol&quot;) #write out as a molfile string and ship that now into rdkit m = Chem.MolFromMolBlock(molblock,removeHs=False,sanitize=True) m.SetProp(&#39;COD&#39;,os.path.basename(filename).split(&quot;.&quot;)[0]) w.write(m) except Exception: pass w.close() def select_molecule(filename): blacklist=[&quot;../../cod/cif/2/31/17/2311717.cif&quot;,&quot;../../cod/cif/2/10/46/2104629.cif&quot;,&quot;../../cod/cif/2/10/59/2105953.cif&quot;] if(filename not in blacklist): try: mol = next(pybel.readfile(&quot;cif&quot;,str(filename))) molblock=mol.write(&quot;mol&quot;) #write out as a molfile string and ship that now into rdkit m = Chem.MolFromMolBlock(molblock,removeHs=False,sanitize=True) if m is not None and len(m.GetSubstructMatches(carbon))&gt;0 and m.GetNumAtoms()&gt; 6 : if(True not in [is_transition_metal(atom) for atom in m.GetAtoms()]): return filename except Exception: return None return None return None if __name__ == &#39;__main__&#39;: files=glob.glob(&#39;../../cod/cif/**/*.cif&#39;, recursive=True) n=0 pool = mp.Pool(mp.cpu_count()) results = pool.map(select_molecule, files) validresults=[el for el in results if el is not None] codids=[int(os.path.basename(filename).split(&quot;.&quot;)[0]) for filename in validresults] df = pd.read_table(&#39;/Users/peter/Downloads/COD_2020jun13.txt&#39;, header=0) dwr=df[&quot;COD Number&quot;] common=list(set(dwr) &amp; set(codids)) write_output(validresults) print(&quot;common molecules&quot;) print(len(common)) import numpy as np print(&quot;in mine, not in datawarrior&quot;) intersect1=np.setdiff1d(codids,dwr) np.savetxt(&quot;out_intersect1.csv&quot;,intersect1.astype(int),delimiter=&quot;,&quot;,fmt=&#39;%i&#39;) print(len(intersect1)) print(&quot;in datawarrior, not in mine&quot;) intersect2=np.setdiff1d(dwr,codids) np.savetxt(&quot;out_intersect2.csv&quot;,intersect2.astype(int),delimiter=&quot;,&quot;,fmt=&#39;%i&#39;) print(len(intersect2)) . I finally decided to strip out the dask code and run it through multiprocessing. Anyhow, easy to set up and a quick discussion on that below as well! . Dask &amp; multiprocessing interlude . Before analyzing the results, let&#39;s briefly assess how dask performs here. Dask enables us to run the code in a classical threaded, but also distributed mode, even on a local machine. As I have 12 cores&#39;s hanging in my MacPro I tested a distributed calculation. That is rather easy to set up. A bit like a multiprocessing Pool, but with the advantage that the functions are not 100% isolated (advantage or disadvantage, I let you decide ;)). The other nice thing (I didn&#39;t know about) is that dask (if installed through conda at least) comes with bokeh, a tool allowing you to do some monitoring of your jobs. It&#39;s not super advanced, but gives you an overview of the worker loads, the job queue and the overall advancement. So that&#39;s quite cool compared to being completely blind on what&#39;s happening in your queue. . . I tested quite a range of combinations and ways to run this in dask (bag, compute, map .... ) and combinations of number of worker nodes vs threads. In the end, parallelization still isn&#39;t optimally spread over all cpu&#39;s, but I guess that&#39;s likely due to the fact that every calculation can range from immediate failure to runnning for a very long time. I guess, that on longer living and more stable jobs this is far more efficient. . The most frustrating thing was that the script completely froze on a single job during the last 10% of the molecules. I narrowed down the issue to 3 molecules that openbabel naturally had issues with. When I say naturally, have a look at these: . . The nasty thing here is that I even tried to kill these freezing jobs with timeout decorators and such. Without success. Even a ctrl+c in a shell didn&#39;t kill the job ... only a kill -9 did. So in the end I kept the multiprocessing version here in the code and filtered out the three incriminating molecules ( by hand, but would be really interested to know how this can be handled in a more geeky way). . Final filtered COD . Let&#39;s come back to the actual aim of this post. Extract torsion angle statistics from small molecule crystal structures. First let&#39;s have a look what molecules I have in common now with Datawarrior and which ones are different and whether the filter should / could be refined a bit. . obabel &amp; rdkit Datawarrior . obabel &amp; rdkit | 78643 | 117674 | . Datawarrior | 117674 | 18344 | . The majority of retained molecules are in common with datawarrior, but I am, I guess still a bit permissive for now. I don&#39;t want to go too much into the analysis of differences here and now. Quickly checking the sd file (above 1Gb) with datawarrior gives a few ideas on what to filter out. I guess I can also use some of the published usual filters on top of that. . . Towards torsion angles . Now the next step is to identify whether there&#39;s enough data to gather some statistics on some typical torsion angles that you can encounter in druglike molecules. Fortunately Sereina Riniker &amp; Greg Landrum already did something a bit similar in the past with data from the CSD and the PDB to write the ETKDG (I hope I got that right) conformer generator for rdkit. . The SI of that paper lists a bunch of smarts patterns describing such torsion angles. I&#39;ll blindly use these here to sieve through all molecules from the COD to see what I can get out of that. The smarts patterns are available here - freely available ... unlike the paper behind it :( . import pandas as pd from rdkit.Chem import rdMolTransforms import matplotlib.pyplot as plt import matplotlib.image as mpimg import numpy as np import urllib.parse torsions=pd.read_table(&quot;../data/list_torsion_patterns.txt&quot;,header=None,usecols=[1]) suppl = Chem.SDMolSupplier(&#39;out.sdf&#39;,removeHs=False) patterns=torsions[1][:3] for torsionSmarts in patterns: print(torsionSmarts) angles=[] torsionQuery = Chem.MolFromSmarts(torsionSmarts) i=0 #suppl.reset() for mol in suppl: i+=1 if mol is None: continue conf=mol.GetConformer(0) matches = mol.GetSubstructMatches(torsionQuery) if(len(matches)&gt;0): for match in matches: angle=rdMolTransforms.GetDihedralDeg(conf, match[0],match[1],match[2],match[3]) angles.append(angle) if(len(angles)): smarts=urllib.parse.quote(torsionSmarts) img = mpimg.imread(&quot;https://smarts.plus/smartsview/download_rest?smarts=&quot;+smarts,format=&quot;png&quot;) fig = plt.figure(figsize=(10, 5)) fig.add_subplot(121) plt.title(&#39;smarts pattern&#39;) plt.axis(&#39;off&#39;) plt.imshow(img) fig.add_subplot(122) plt.title(&#39;torsion angle histogram&#39;) #df = pd.DataFrame(angles,columns = [torsionSmarts]) plt.hist(np.array(angles),bins=36,range=[-180, 180]) . . I&#39;m only showing 3 smarts patterns here, but the code is written to run on all of the smarts patterns from the Riniker &amp; Landrum paper. So feel free to adjust it to get the full results on your machine (to big for the notebook here ;). . As you can see, there is still a lot of errors when re-reading the molecules from the SD file ... so still a lot of curation to be done. Also, on fullerenes or graphene or other larger structures (that are still in there), we&#39;ll likely get a repeated overrepresentation of several torsion angles. So something to think about when normalizing all of this data in the end. . In theory, the order of the smarts patterns in the file I used here should be comparable to torsion angles provided in the S1.zip by both authors (fingers crossed). These histograms were generated on a filtered / curated CCDC CSD dataset (unlike my hairy monster dataset here). . . The first thing to notice is that they calculated a dihedral between 0 and 360, I just took the angles popping out of rdkit (between -180 and 180). So a bit of a mindgame to compare both. On smarts patterns 1 and 3 we have peaks around 0, which coincides with the CSD results. It is interesting to see that there&#39;s a bit of data for smarts pattern 1 suggesting angles around 180° might be possible, though not favourable (again, more filtering and quality checks needed to confirm/discard that). . Smarts pattern 2 doesn&#39;t coincide at all with results from the CSD however, which makes me worried ... a bit ;) . Debugging smarts pattern 2 . pattern=&quot;[O:1]=[C:2]([N])!@;-[O:3]~[C:4]&quot; i=0 torsionQuery = Chem.MolFromSmarts(pattern) for mol in suppl: i+=1 if mol is None: continue conf=mol.GetConformer(0) matches = mol.GetSubstructMatches(torsionQuery) if(len(matches)): for match in matches: angle=rdMolTransforms.GetDihedralDeg(conf, match[0],match[1],match[2],match[3]) #break print(angle) print(mol.GetProp(&quot;COD&quot;)) if(i&gt;5000): break . 178.94640626006364 7031170 -177.12326809469428 7039689 -179.7556421050122 7039689 -179.06730293018322 7039689 . Here are 4 compounds where we calculate in theory wrong angles. Let&#39;s visualize the last one and check what dihedral angle we are actually calculating here . for mol in suppl: if str(mol.GetProp(&quot;COD&quot;))==str(7039689): mol.GetSubstructMatches(torsionQuery) break matches=mol.GetSubstructMatches(torsionQuery) print(matches) flat_list = [item for sublist in matches for item in sublist] molblock=Chem.MolToMolBlock(mol) viewer = py3Dmol.view(width=300, height=300) viewer.addModel(molblock, &#39;mol&#39;) viewer.setStyle({&quot;stick&quot;:{}}) #viewer.setStyle({&#39;serial&#39;:flat_list},{&#39;stick&#39;:{&#39;color&#39;: &#39;pink&#39;}}) viewer.setStyle({&#39;serial&#39;:flat_list},{&#39;stick&#39;:{&#39;color&#39;: &#39;pink&#39;}}) viewer.zoomTo() . ((1, 18, 4, 0, 19), (53, 70, 56, 52, 71), (105, 122, 108, 104, 123)) . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7fc980882130&gt; . The matching atoms are coloured in pink here. . From the substructure matches above, we can see that the smarts pattern matches 5 atoms, instead of 4. Including the nitrogen (the third atom matching here). In the end, this doesn&#39;t describe the bond or the torsion angle we want at all, thus the discrepancies in the results. . Conclusion . Alright, this turned out to be much messier than I thought. However, extracting statistics from the COD seems possible, even though there should be a lot careful curation steps integrated when doing something like that. I&#39;ll try to dig through the results during the next days and will try to report whether patterns published before using the CSD can be reproduced or not (to some extent). . The steps outlined here should also provide a first automated pipeline to select relevant compounds from the COD for regular updates of the potentials - which I do hope will be helpful on the long run for some folks. . PS . This post yielded a few reactions online, which is great. Thanks for Jesus Seco pointing out a paper I missed, as usual, from Wolfgang Guba on a more refined set of torsion angle defining smarts patterns, if you have access to that. Fortunately the SI is freely available and contains an xml file with all the smarts patterns and even a traffic light (score) system for given ranges of angles. From my understanding in the description of the SI, only the histogram from the CSD was stripped from that file, but the statistics and preferred angles are derived from the CSD. So an excellent set to be used &amp; to be compared to what we can extract from the COD. . &lt;torsionRule smarts=&quot;[*:1]~[CX4:2]!@[n:3]~[*:4]&quot;&gt; &lt;angleList&gt; &lt;angle value=&quot;0.0&quot; tolerance1=&quot;30.00&quot; tolerance2=&quot;30.00&quot; score=&quot;3.07&quot;/&gt; &lt;angle value=&quot;60.0&quot; tolerance1=&quot;30.00&quot; tolerance2=&quot;30.00&quot; score=&quot;3.55&quot;/&gt; &lt;angle value=&quot;120.0&quot; tolerance1=&quot;30.00&quot; tolerance2=&quot;30.00&quot; score=&quot;3.12&quot;/&gt; &lt;angle value=&quot;180.0&quot; tolerance1=&quot;30.00&quot; tolerance2=&quot;30.00&quot; score=&quot;3.54&quot;/&gt; &lt;angle value=&quot;-60.0&quot; tolerance1=&quot;30.00&quot; tolerance2=&quot;30.00&quot; score=&quot;3.65&quot;/&gt; &lt;angle value=&quot;-120.0&quot; tolerance1=&quot;30.00&quot; tolerance2=&quot;30.00&quot; score=&quot;3.1&quot;/&gt; &lt;/angleList&gt; &lt;/torsionRule&gt; . PS2 . Geoff Hutchison took the torsion smarts extraction part a bit further following up this post. This should remap the matching atoms from the smarts pattern match correctly and avoid the caveat that I observed for the smarts pattern #2 above: . https://gist.github.com/ghutchis/b388dd83ddcd7dc0be11f1ed72309da2 .",
            "url": "https://pschmidtke.github.io/blog/rdkit/crystallography/small%20molecule%20xray/xray/database/2021/01/25/cod-and-torsion-angles.html",
            "relUrl": "/rdkit/crystallography/small%20molecule%20xray/xray/database/2021/01/25/cod-and-torsion-angles.html",
            "date": " • Jan 25, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Grafting fragments onto molecules in rdkit - babysteps",
            "content": "Context . In this quick walkthrough I describe the first steps to attach fragments from a fragment library onto a molecule of interest. The main idea here is to prepare code snippets for the integration of all of this into the web-based 3d-editor project I started with Daniel Alvarez some time ago. As I&#39;m learning a lot of new things about rdkit I prefer to write it up here, as I found most of the relevant information in the mailing list &amp; the rdkit documentation. . The molecule to modify . I&#39;ll go for the same molecule as the one used for now in our BRD4 structure of the 3d editor project - that just comes from one of the official openforcefield examples here. . The fragment to add . I wanted to go for something easy for now ... so let&#39;s start with a methyl group ;) I made a quick shoutout on twitter on current available 3D fragments that could be helpful to write such a sketcher. Geoff Hutchison (Mr Avogadro) gave me a great hint to this library here. It contains way more fragments than I&#39;d initially considered for this project and the coordinates seem reasonable &amp; compatible with the systems we&#39;ll manage in the 3d-editor. . So I just took the methane from there (for now), ran it through Marvinsketch to replace one of the protons with an R group and then exported the whole thing as mol file (to the best of my knowledge rdkit doesn&#39;t support the chemistry markup language yet). . Preliminary steps . # https://sourceforge.net/p/rdkit/mailman/message/34922663/ procedure extracted from this support request import rdkit from rdkit import Chem from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw IPythonConsole.ipython_useSVG=True import py3Dmol from rdkit.Chem import AllChem import copy from rdkit.Chem.rdMolAlign import AlignMol . . Below, the molecule we want to add the methyl group to. We&#39;ll attach it on the triazole ring. . suppl = Chem.SDMolSupplier(&#39;../data/ligand.sdf&#39;,removeHs=False) for mol in suppl: mblock = Chem.MolToMolBlock(mol) viewer = py3Dmol.view(width=300, height=300) viewer.addModel(mblock, &#39;mol&#39;) viewer.setStyle({&quot;stick&quot;:{}}) viewer.zoomTo() . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f9a708b8e50&gt; . As the aim is to integrate that into the 3D-editor, the user ultimately will be able to click on the proton where he wants to place the fragment. Thus, we know which exact atom we want to attach it to. Below I&#39;m determining this showing plain atom indices in the rdkit molecule . for atom in mol.GetAtoms(): atom.SetAtomMapNum(atom.GetIdx()) mol2d=copy.deepcopy(mol) AllChem.Compute2DCoords(mol2d) #do this on a copy here Draw.MolToImage(mol2d, includeAtomNumbers=True) . Next I&#39;m loading the fragment and extract the position of the R-group and the connected atom as atom indices (I&#39;ll need that later). I know this is very limited and ugly for now, but it serves the purpose here &amp; now ;) . def getAttachmentVector(mol): &quot;&quot;&quot; for a fragment to add, search for the position of the attachment point and extract the atom id&#39;s of the attachment point and the connected atom (currently only single bond supported) mol: fragment passed as rdkit molecule return: tuple (atom indices) &quot;&quot;&quot; rindex=-1 rindexNeighbor=-1 for atom in mol.GetAtoms(): if(atom.GetAtomicNum()==0): rindex=atom.GetIdx() neighbours=atom.GetNeighbors() if(len(neighbours)==1): rindexNeighbor=neighbours[0].GetIdx() else: print(&quot;two attachment points not supported yet&quot;) return None return((rindex,rindexNeighbor)) fragment=Chem.MolFromMolFile(&#39;../data/methyl.mol&#39;,removeHs=False) ret=getAttachmentVector(fragment) for atom in mol.GetAtoms(): atom.SetAtomMapNum(atom.GetIdx()) if(ret): fragIndex1,fragIndex2=ret print(fragIndex1, fragIndex2) mblock = Chem.MolToMolBlock(fragment) viewer = py3Dmol.view(width=300, height=300) viewer.addModel(mblock, &#39;mol&#39;) viewer.setStyle({&quot;stick&quot;:{}}) viewer.zoomTo() . 4 1 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f9a40d3b310&gt; . Now let&#39;s extract also the atom index of the proton, and also the carbon the proton is attached to on the molecule. . queryAtomIndex=20 #defined by clicking on an atom in the sketcher -&gt; needs to be a proton right now for grafting atom=mol.GetAtomWithIdx(queryAtomIndex) neighbours=atom.GetNeighbors() if(len(neighbours)==1): rindexNeighbor=neighbours[0].GetIdx() else: print(&quot;two attachment points not supported yet&quot;) molIndex1=queryAtomIndex molIndex2=rindexNeighbor print(molIndex1,molIndex2) . 20 9 . Aligning the fragment onto the molecule . Now I have the bond of the carbon to proton selected in the molecule and the carbon to R-group in my fragment. These bonds can be aligned onto each other to position the 3D-fragment correctly versus the molecule. This can be conveniently done using the AlignMol function available in rdkit. . AlignMol(fragment,mol,atomMap=((fragIndex2,molIndex1),(fragIndex1,molIndex2))) #important to specify the atomMap here, this aligns only the bonds . 0.027497679760887607 . #the rest is just to display things here mblock = Chem.MolToMolBlock(mol) fragblock = Chem.MolToMolBlock(fragment) viewer = py3Dmol.view(width=500, height=500) viewer.addModel(mblock, &#39;mol&#39;) viewer.addModel(fragblock, &#39;mol&#39;) viewer.setStyle({&quot;stick&quot;:{}}) viewer.zoomTo() . . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f9a80a95e10&gt; . As you can see, the fragment gets placed correctly on top of the proton. Now we have however a few overlapping atoms in place. We can use the rdkit edition functions to address this and combine both overlapping molecules now into a final single molecule. . def connectMols(mol1, mol2, atom1, atom2): &quot;&quot;&quot;function copied from here https://github.com/molecularsets/moses/blob/master/moses/baselines/combinatorial.py&quot;&quot;&quot; combined = Chem.CombineMols(mol1, mol2) emol = Chem.EditableMol(combined) neighbor1_idx = atom1.GetNeighbors()[0].GetIdx() neighbor2_idx = atom2.GetNeighbors()[0].GetIdx() atom1_idx = atom1.GetIdx() atom2_idx = atom2.GetIdx() bond_order = atom2.GetBonds()[0].GetBondType() emol.AddBond(neighbor1_idx, neighbor2_idx + mol1.GetNumAtoms(), order=bond_order) emol.RemoveAtom(atom2_idx + mol1.GetNumAtoms()) emol.RemoveAtom(atom1_idx) mol = emol.GetMol() return mol finalMol=connectMols(mol,fragment,mol.GetAtomWithIdx(molIndex1),fragment.GetAtomWithIdx(fragIndex1)) Chem.SanitizeMol(finalMol) finalMolBlock = Chem.MolToMolBlock(finalMol) viewer = py3Dmol.view(width=500, height=500) viewer.addModel(finalMolBlock, &#39;mol&#39;) viewer.setStyle({&quot;stick&quot;:{}}) viewer.zoomTo() . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . &lt;py3Dmol.view at 0x7f9a80a8b790&gt; . And voilà. Our methyl is nicely placed and oriented. That&#39;s one of the easiest cases and we&#39;ll have to consider torsion angles &amp; protein environment at a later stage as well, but this should provide first basic steps for simple additions like the one done here. .",
            "url": "https://pschmidtke.github.io/blog/rdkit/3d-editor/2021/01/23/grafting-fragments.html",
            "relUrl": "/rdkit/3d-editor/2021/01/23/grafting-fragments.html",
            "date": " • Jan 23, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About myself . I’m a European citizen, dad of two beautiful girls and I am currently stranded in France. I did my PhD in Xavier Barril’s excellent group at the University of Barcelona, then a post-doc in molecular modelling within a French pharma company. However, I spent most of my “professional career” at Discngine based in Paris, France. A great place to work, even though we tend not to apply for these fancy marketing labels ;) . Together with Vincent Le Guilloux (also at Discngine now) we developed fpocket while we were still finishing our Bioinformatics Masters degree. After that I wrote a bunch of papers (during my PhD) mainly on binding site characterisation, druggability assessment, structure kinetic relationships and a couple of other things more. . Together with a great team at Discngine, I also started 3decision a subscription-based structure repo &amp; analytics platform a few years back now. . About this blog . During my everyday work I’m in contact with a lot of people supporting early stage drug discovery. During this work I use proprietary tools, but also several open source tools. Usually you face several issues a lot of other people faced before or will face in the future. One aim of this blog is to share these quirks and allow others to gain some time, trigger discussions, get feedback and improve the field as openly as possible. . I’ll likely write about whatever crosses my mind here, but it’ll surely focus on topics around cheminformatics, bioinformatics, binding sites, maybe a few papers. Let’s see where this goes. . Spinning coral . The name of the blog was inspired by my 7 years old daughter, Anna. She always wants to play with 3D molecular viewers on my screen. She started to do that when she was around 5, having no idea what a protein is and looks like she basically asks me: “Daddy, may I spin the coral again?”. . Inspirations . Having a blog on cheminformatics etc is not the brightest and newest idea. I’ve had a lot of good reads thanks to all of these excellent &amp; very well known blogs: . https://iwatobipen.wordpress.com/ | http://practicalcheminformatics.blogspot.com/ | https://greglandrum.github.io/rdkit-blog/ | . This website is powered by fastpages and github. .",
          "url": "https://pschmidtke.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "About",
          "content": "About this blog . During my everyday work I’m in contact with a lot of people supporting early stage drug discovery. During this work I use proprietary tools, but also several open source tools. Usually you face several issues a lot of other people faced before or will face in the future. One aim of this blog is to share these quirks and allow others to gain some time, trigger discussions, get feedback and improve the field as openly as possible. . I’ll likely write about whatever crosses my mind here, but it’ll surely focus on topics around cheminformatics, bioinformatics, binding sites, maybe a few papers. Let’s see where this goes. . About myself . I’m a European citizen, dad of two beautiful girls and I am currently stranded in France. I did my PhD in Xavier Barril’s excellent group at the University of Barcelona, then a post-doc in molecular modelling within a French pharma company. However, I spent most of my “professional career” at Discngine based in Paris, France. A great place to work, even though we tend not to apply for these fancy marketing labels ;) . Together with Vincent Le Guilloux (also at Discngine now) we developed fpocket while we were still finishing our Bioinformatics Masters degree. After that I wrote a bunch of papers (during my PhD) mainly on binding site characterisation, druggability assessment, structure kinetic relationships and a couple of other things more. . Together with a great team at Discngine, I also started 3decision a subscription-based structure repo &amp; analytics platform a few years back now. . Spinning coral . The name of the blog was inspired by my 7 years old daughter, Anna. She always wants to play with 3D molecular viewers on my screen. She started to do that when she was around 5, having no idea what a protein is and looks like she basically asks me: “Daddy, may I spin the coral again?”. . Inspirations . Having a blog on cheminformatics etc is not the brightest and newest idea. I’ve had a lot of good reads thanks to all of these excellent &amp; very well known blogs: . https://iwatobipen.wordpress.com/ | http://practicalcheminformatics.blogspot.com/ | https://greglandrum.github.io/rdkit-blog/ | .",
          "url": "https://pschmidtke.github.io/blog/quarto/about.qmd",
          "relUrl": "/quarto/about.qmd",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "",
          "content": "Posts .",
          "url": "https://pschmidtke.github.io/blog/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
      ,"page4": {
          "title": "Forced revamp ongoing",
          "content": "This blog is under migration to quarto. . . I initially used fastai’s fastpages framework to run &amp; expose jupyter notebooks as blog posts here. Unfortunately fastpages was discontinued a while ago and I got a bit fed up investigating &amp; fixing github actions etc everytime I want to post an article. As suggested by the fastpages author, I’m thus discovering &amp; migrating to quarto. which looks indeed very nice. . While doing that i also noticed that the 3D rendering py3dmol library I was using doesn’t work as well anymore - so will switch also gradually. So please do not be alarmed if you see dramatic changes in layout etc during the next days ;) .",
          "url": "https://pschmidtke.github.io/blog/quarto/posts/welcome/index.qmd",
          "relUrl": "/quarto/posts/welcome/index.qmd",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "Spinning coral",
          "content": "",
          "url": "https://pschmidtke.github.io/blog/quarto/index.qmd",
          "relUrl": "/quarto/index.qmd",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page14": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pschmidtke.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}